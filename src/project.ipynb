{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_and_standardize_data\n",
    "import classifier as cl\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classifiers.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    classifier_params = ['num', 'kruskall', 'one_vs?', 'distance_type', 'algorithm']\n",
    "    writer.writerow(classifier_params)\n",
    "    classifier1 = ['1','yes', 'one_vs_all', 'euclidean', 'none']\n",
    "    writer.writerow(classifier1)\n",
    "    classifier2 = ['2','no', 'one_vs_all', 'euclidean', 'none']\n",
    "    writer.writerow(classifier2)\n",
    "    classifier3 = ['3','yes', 'one_vs_all', 'mahalanobis', 'none']\n",
    "    writer.writerow(classifier3)\n",
    "    classifier4 = ['4','no', 'one_vs_all', 'mahalanobis', 'none']\n",
    "\n",
    "    writer.writerow(classifier4)\n",
    "    classifier5 = ['5','yes', 'one_vs_all', 'none', 'naive_bayes']\n",
    "    writer.writerow(classifier5)\n",
    "    classifier6 = ['6','no', 'one_vs_all', 'none', 'naive_bayes']\n",
    "    writer.writerow(classifier6)\n",
    "    classifier7 = ['7','yes', 'one_vs_one', 'none', 'naive_bayes']\n",
    "    writer.writerow(classifier7)\n",
    "    classifier8 = ['8','no', 'one_vs_one', 'none', 'naive_bayes']\n",
    "    writer.writerow(classifier8)\n",
    "\n",
    "    classifier9 = ['9','yes', 'one_vs_all', 'none', 'knn']\n",
    "    writer.writerow(classifier9)\n",
    "    classifier10 = ['10','no', 'one_vs_all', 'none', 'knn']\n",
    "    writer.writerow(classifier10)\n",
    "    classifier11 = ['11','yes', 'one_vs_one', 'none', 'knn']\n",
    "    writer.writerow(classifier11)\n",
    "    classifier12 = ['12','no', 'one_vs_one', 'none', 'knn']\n",
    "    writer.writerow(classifier12)\n",
    "\n",
    "    classifier13 = ['13','yes', 'one_vs_all', 'none', 'svm']\n",
    "    writer.writerow(classifier13)\n",
    "    classifier14 = ['14','no', 'one_vs_all', 'none', 'svm']\n",
    "    writer.writerow(classifier14)\n",
    "    classifier15 = ['15','yes', 'one_vs_one', 'none', 'svm']\n",
    "    writer.writerow(classifier15)\n",
    "    classifier16 = ['16','no', 'one_vs_one', 'none', 'svm']\n",
    "    writer.writerow(classifier16)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    res = ['sensivity', 'specificity', 'precision']\n",
    "    writer.writerow(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m0\u001b[39m, X_test\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[1;32m     14\u001b[0m     model: cl\u001b[39m.\u001b[39mClassifier \u001b[39m=\u001b[39m cl\u001b[39m.\u001b[39mClassifier(X_train, y_train)\n\u001b[0;32m---> 16\u001b[0m     model\u001b[39m.\u001b[39;49mfeature_selection(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     18\u001b[0m     \u001b[39mif\u001b[39;00m reduction \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     19\u001b[0m         model\u001b[39m.\u001b[39mfeature_reduction(reduction)\n",
      "File \u001b[0;32m~/dev/rp_project/src/classifier.py:43\u001b[0m, in \u001b[0;36mClassifier.feature_selection\u001b[0;34m(self, n_components)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeature_selection\u001b[39m(\u001b[39mself\u001b[39m, n_components: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pre_processed_train_X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__feature_selection(\n\u001b[1;32m     44\u001b[0m         X\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pre_processed_train_X, y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__train_y, n_components\u001b[39m=\u001b[39;49mn_components\n\u001b[1;32m     45\u001b[0m     )\n",
      "File \u001b[0;32m~/dev/rp_project/src/classifier.py:48\u001b[0m, in \u001b[0;36mClassifier.__feature_selection\u001b[0;34m(self, X, y, n_components)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__feature_selection\u001b[39m(\u001b[39mself\u001b[39m, X: np\u001b[39m.\u001b[39mndarray, y: np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, n_components: \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__feature_selection_model, result \u001b[39m=\u001b[39m pre_processing\u001b[39m.\u001b[39;49mcomput_kruskal(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__feature_selection_model, n_components\u001b[39m=\u001b[39;49mn_components)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/dev/rp_project/src/pre_processing.py:63\u001b[0m, in \u001b[0;36mcomput_kruskal\u001b[0;34m(X, y, model, n_components)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIf no model is given, it is necessary the labels to train one\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[1;32m     61\u001b[0m     kw: KruskalWallis \u001b[39m=\u001b[39m KruskalWallis(n_components)\n\u001b[0;32m---> 63\u001b[0m     kw\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my)\n\u001b[1;32m     64\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     kw \u001b[39m=\u001b[39m model\n",
      "File \u001b[0;32m~/dev/rp_project/src/kruskal_wallis.py:25\u001b[0m, in \u001b[0;36mKruskalWallis.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     21\u001b[0m     classes_values \u001b[39m=\u001b[39m classes_values \u001b[39m+\u001b[39m (this_feature[label \u001b[39m==\u001b[39m y],)\n\u001b[1;32m     23\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39m# run kruskal wallis\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m     result \u001b[39m=\u001b[39m kruskal(\u001b[39m*\u001b[39;49mclasses_values)\n\u001b[1;32m     27\u001b[0m     \u001b[39m# 95% confidence interval - p-value < 0.01\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m result[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m \u001b[39m0.05\u001b[39m:\n",
      "File \u001b[0;32m~/dev/rp_project/env/lib/python3.11/site-packages/scipy/stats/_axis_nan_policy.py:502\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[39mif\u001b[39;00m sentinel:\n\u001b[1;32m    501\u001b[0m     samples \u001b[39m=\u001b[39m _remove_sentinel(samples, paired, sentinel)\n\u001b[0;32m--> 502\u001b[0m res \u001b[39m=\u001b[39m hypotest_fun_out(\u001b[39m*\u001b[39;49msamples, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    503\u001b[0m res \u001b[39m=\u001b[39m result_to_tuple(res)\n\u001b[1;32m    504\u001b[0m res \u001b[39m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n",
      "File \u001b[0;32m~/dev/rp_project/env/lib/python3.11/site-packages/scipy/stats/_stats_py.py:8614\u001b[0m, in \u001b[0;36mkruskal\u001b[0;34m(nan_policy, *samples)\u001b[0m\n\u001b[1;32m   8612\u001b[0m alldata \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(samples)\n\u001b[1;32m   8613\u001b[0m ranked \u001b[39m=\u001b[39m rankdata(alldata)\n\u001b[0;32m-> 8614\u001b[0m ties \u001b[39m=\u001b[39m tiecorrect(ranked)\n\u001b[1;32m   8615\u001b[0m \u001b[39mif\u001b[39;00m ties \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   8616\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAll numbers are identical in kruskal\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/rp_project/env/lib/python3.11/site-packages/scipy/stats/_stats_py.py:8420\u001b[0m, in \u001b[0;36mtiecorrect\u001b[0;34m(rankvals)\u001b[0m\n\u001b[1;32m   8383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtiecorrect\u001b[39m(rankvals):\n\u001b[1;32m   8384\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Tie correction factor for Mann-Whitney U and Kruskal-Wallis H tests.\u001b[39;00m\n\u001b[1;32m   8385\u001b[0m \n\u001b[1;32m   8386\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   8418\u001b[0m \n\u001b[1;32m   8419\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 8420\u001b[0m     arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49msort(rankvals)\n\u001b[1;32m   8421\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(np\u001b[39m.\u001b[39mr_[\u001b[39mTrue\u001b[39;00m, arr[\u001b[39m1\u001b[39m:] \u001b[39m!=\u001b[39m arr[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], \u001b[39mTrue\u001b[39;00m])[\u001b[39m0\u001b[39m]\n\u001b[1;32m   8422\u001b[0m     cnt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdiff(idx)\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat64)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msort\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/dev/rp_project/env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1030\u001b[0m, in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1029\u001b[0m     a \u001b[39m=\u001b[39m asanyarray(a)\u001b[39m.\u001b[39mcopy(order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mK\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1030\u001b[0m a\u001b[39m.\u001b[39;49msort(axis\u001b[39m=\u001b[39;49maxis, kind\u001b[39m=\u001b[39;49mkind, order\u001b[39m=\u001b[39;49morder)\n\u001b[1;32m   1031\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X_train, X_test, y_train, y_test = read_and_standardize_data(True, \"blues\")\n",
    "with open('results.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    res = ['label', 'num_features', 'reduction_methos', 'sensivity', 'specificity', 'precision']\n",
    "    writer.writerow(res)\n",
    "\n",
    "for label in [\"blues\", \"classical\", \"country\", \"disco\", \"hiphop\", \"jazz\", \"metal\", \"pop\", \"reggae\", \"rock\"]:\n",
    "\n",
    "    X_train, X_test, y_train, y_test = read_and_standardize_data(True, label)\n",
    "\n",
    "    for reduction in [\"None\", \"PCA\", \"LDA\"]:\n",
    "        for i in range (0, X_test.shape[1]):\n",
    "\n",
    "            model: cl.Classifier = cl.Classifier(X_train, y_train)\n",
    "\n",
    "            model.feature_selection(i+1)\n",
    "\n",
    "            if reduction != \"None\":\n",
    "                model.feature_reduction(reduction)\n",
    "\n",
    "            #model.train(\"one_vs_all\", distance_type=\"mahalanobis\")\n",
    "            model.train(\"one_vs_all\", distance_type=\"euclidean\")\n",
    "\n",
    "            model.predict(X_test)\n",
    "\n",
    "            # stats = model.get_statistics(y_test, True).values()\n",
    "            stats = model.get_statistics(y_test, False)\n",
    "\n",
    "            # print(f\"number features:{i} Feature Reduction: {reduction} Stats: {stats}\")\n",
    "\n",
    "            with open('results.csv', 'a') as f:\n",
    "                # 'a' instead of 'w' makes things append instead of ovewriting\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([label, i+1, reduction, stats['sensitivity'], stats['specificity'], stats['precision']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.csv', 'a') as f:\n",
    "    # 'a' instead of 'w' makes things append instead of ovewriting\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(stats)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
